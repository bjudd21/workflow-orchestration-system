# ============================================================
# Workflow Orchestration System — Environment Configuration
# ============================================================
# Copy this file to .env and update values as needed.
# For True MVP, only the n8n and Ollama sections are required.

# ---- n8n Configuration ----
N8N_BASIC_AUTH_ACTIVE=true
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=changeme
N8N_ENCRYPTION_KEY=generate-a-random-string-here
TIMEZONE=America/New_York

# ---- Ollama (Local Inference — True MVP) ----
# Ollama runs on the WSL2 host, accessible from Docker via host networking.
# No API key required. Models must be pulled first:
#   ollama pull qwen3.5:27b        (~18GB, quality model)
#   ollama pull qwen3.5:35b-a3b    (~21GB, speed model)
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_SPEED_MODEL=qwen3.5:35b-a3b
OLLAMA_QUALITY_MODEL=qwen3.5:27b

# ---- Full MVP: API Providers (Optional) ----
# Uncomment and configure when adding cloud API fallback.

# Anthropic API (Claude Opus, Sonnet, Haiku)
# ANTHROPIC_API_KEY=sk-ant-...

# AWS Bedrock (Claude models in gov/compliance environments)
# AWS_ACCESS_KEY_ID=AKIA...
# AWS_SECRET_ACCESS_KEY=...
# AWS_REGION=us-east-1

# OpenAI-compatible endpoint (LM Studio, vLLM, text-generation-webui)
# OPENAI_COMPATIBLE_BASE_URL=http://localhost:1234/v1
# OPENAI_COMPATIBLE_API_KEY=not-needed-for-local
